{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project Introduction Part 2\n",
    "\n",
    "Having experimented with the NLTK library and rudimentary generative models in Part 1 greater light was shed on the Presidential Primary debates. Part 2 aims to further elaborate with more investigation and experimentation with Natural Language Processing techniques. The final aims is to see whether the candidates' language from the debates can gain predictive insight into their language on Twitter. This leap across data boundaries will then define the direction of the final Capstone Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/debate.csv', encoding = \"ISO-8859-1\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Holt</td>\n",
       "      <td>Good evening from Hofstra University in Hempst...</td>\n",
       "      <td>9/26/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Audience</td>\n",
       "      <td>(APPLAUSE)</td>\n",
       "      <td>9/26/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>How are you, Donald?</td>\n",
       "      <td>9/26/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Audience</td>\n",
       "      <td>(APPLAUSE)</td>\n",
       "      <td>9/26/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Holt</td>\n",
       "      <td>Good luck to you.</td>\n",
       "      <td>9/26/16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line   Speaker                                               Text     Date\n",
       "0     1      Holt  Good evening from Hofstra University in Hempst...  9/26/16\n",
       "1     2  Audience                                         (APPLAUSE)  9/26/16\n",
       "2     3   Clinton                               How are you, Donald?  9/26/16\n",
       "3     4  Audience                                         (APPLAUSE)  9/26/16\n",
       "4     5      Holt                                  Good luck to you.  9/26/16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl_list = []\n",
    "\n",
    "def remove_words(input):\n",
    "    words = ['donald', 'clinton', 'trump', 'hillary', 'his', 'her', \"she's\", 'she', 'he', \"he's\"]\n",
    "    querywords = input.split()\n",
    "\n",
    "    resultwords  = [word for word in querywords if word.lower() not in words]\n",
    "    result = ' '.join(resultwords)\n",
    "    return result \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row[1] == 'Clinton':\n",
    "        text = remove_words(row[2])\n",
    "        cl_list.append((text.lower(), 'Clinton'))\n",
    "    elif row[1] == 'Trump':\n",
    "        text = remove_words(row[2])\n",
    "        cl_list.append((text.lower(), 'Trump'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = len(cl_list)\n",
    "split = int(length*4/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=cl_list[:split]\n",
    "test=cl_list[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775\n"
     ]
    }
   ],
   "source": [
    "print(cl.accuracy(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        contains(worked) = True           Clinto : Trump  =     11.8 : 1.0\n",
      "          contains(part) = True           Clinto : Trump  =     10.8 : 1.0\n",
      "      contains(disaster) = True            Trump : Clinto =     10.2 : 1.0\n",
      "           contains(bad) = True            Trump : Clinto =     10.2 : 1.0\n",
      "      contains(everyone) = True           Clinto : Trump  =      9.9 : 1.0\n",
      "         contains(still) = True           Clinto : Trump  =      8.9 : 1.0\n",
      "      contains(security) = True           Clinto : Trump  =      8.9 : 1.0\n",
      "       contains(support) = True           Clinto : Trump  =      8.2 : 1.0\n",
      "          contains(vote) = True           Clinto : Trump  =      8.0 : 1.0\n",
      "          contains(paid) = True           Clinto : Trump  =      8.0 : 1.0\n",
      "      contains(military) = True           Clinto : Trump  =      8.0 : 1.0\n",
      "         contains(tried) = True           Clinto : Trump  =      7.1 : 1.0\n",
      "          contains(home) = True           Clinto : Trump  =      7.1 : 1.0\n",
      "       contains(working) = True           Clinto : Trump  =      7.1 : 1.0\n",
      "        contains(system) = True           Clinto : Trump  =      6.5 : 1.0\n",
      "      contains(american) = True           Clinto : Trump  =      6.4 : 1.0\n",
      "         contains(close) = True           Clinto : Trump  =      6.1 : 1.0\n",
      "         contains(lives) = True           Clinto : Trump  =      6.1 : 1.0\n",
      "          contains(both) = True           Clinto : Trump  =      6.1 : 1.0\n",
      "          contains(kind) = True           Clinto : Trump  =      6.1 : 1.0\n",
      "      contains(election) = True           Clinto : Trump  =      5.9 : 1.0\n",
      "        contains(almost) = True            Trump : Clinto =      5.9 : 1.0\n",
      "        contains(making) = True           Clinto : Trump  =      5.4 : 1.0\n",
      "          contains(sure) = True           Clinto : Trump  =      5.4 : 1.0\n",
      "       contains(america) = True           Clinto : Trump  =      5.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having used TextBlob to run a Naive Bayes Classifier on the Presidential text, while eliminating trivial words, we can yield even greater insight into how the use of vocabulary has differentied the respective candidates. Clinton's greater lexical diversity as indicated in the Data Story is demonstrated most here. Given a much greater volume of text and more udnerstanding of the technology perhaps a vectorised model could be trained to spot an even greater depth of features and perhaps a generative model could be trained also. In light of my current limitations I will stop here, but I think a great deal of previously unrecognised insight has been revealed on this dataset with just this brief and experimental approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv('data/tweets.csv')\n",
    "tweet_list = []\n",
    "\n",
    "for index, row in df_tweets.iterrows():\n",
    "    if row[1] == 'HillaryClinton':\n",
    "        text = remove_words(row[2])\n",
    "        tweet_list.append((text.lower(), 'Clinton'))\n",
    "    elif row[1] == 'realDonaldTrump':\n",
    "        text = remove_words(row[2])\n",
    "        tweet_list.append((text.lower(), 'Trump'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cl.accuracy(tweet_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having wrangled the tweets it seems that the trained classifier from the debates yields no greater insight into the language used in tweets than a coin-flip! Surprised? Well... let's train a classifier on the Tweets themselves and see what vocabulary is more predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = len(tweet_list)\n",
    "split = int(length*4/5)\n",
    "train_tweets=tweet_list[:split]\n",
    "test_tweets=tweet_list[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_cl = NaiveBayesClassifier(train_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweet_cl.accuracy(test_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_cl.show_informative_features(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the predictive features of the text in the tweets that Donald Trump's use of words is much more radicalised. He repeatedly calls out his opponents, Republican and Democrat, by name, and uses much more divise, colloquial and extreme language. It's well known that Trump's shrewd use of social media, with Cambridge Analytics in particular, helped to propel him in the polls. Dissociative Identity Disorder or Crazy like a Fox? Probably the latter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv('data/tweets.csv')\n",
    "h_tweet_str = \" \"\n",
    "t_tweet_str = \" \"\n",
    "import re \n",
    "\n",
    "def remove_link(input):\n",
    "    result = re.sub(r'http\\S+','', input)\n",
    "    return result\n",
    "\n",
    "for index, row in df_tweets.iterrows():\n",
    "    if row[1] == 'HillaryClinton':\n",
    "        text = remove_words(row[2])\n",
    "        text = remove_link(text)\n",
    "        h_tweet_str += text.lower()\n",
    "    elif row[1] == 'realDonaldTrump':\n",
    "        text = remove_words(row[2])\n",
    "        text = remove_link(text)\n",
    "        t_tweet_str += text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=70).generate(t_tweet_str)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Trump's tweet word cloud is significantly different from the word cloud prodocued in the Presidential debates. Phrases we all remember like 'Make America Great Again' and 'Crooked Hillary' feature alongside 'Fake News' and Obama, CNN and Ted Cruz. This is all much more what we associate with the 'saga' of the debate, with Trump being the angry populist championing the cause of the downtrodden masses against the establishment. Maybe it has become easier for meaningful views to be expressed via social media than on TV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=70).generate(h_tweet_str)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In contrast we can see that Hillary's tweets are more measured. There is nothing in here conveying emnity or radical change. It's all very much what one would expect from a centre left politician. Trump's Word Cloud is much more 'remarkable' than Hillary's which again reflects the rise of social media and digital marketing in politics. Seth Godin would be much more likely to approve of Trump's tweets from a 'Purple Cow' perspective than Hillary's even regardless of the issues. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this preliminary analysis it would seem that Donald Trump was more effective at adapting his communication style according to the platform and medium he was using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being unable to find significant features to link Twitter classification has derailed the final direction of Capstone project but it has yielded insight into the impact of social media in politics. Also I have learned that a Data Scientist needs to be able to draw from their own experience, contextual understanding and insight to be able to draw conclusions from data. The tools are useful but a Data Scentist should not be overly reliant upon them. A good data scientist should have a good understanding of the subject matter in hand and be prepared for his conclusions to be challenged. \n",
    "\n",
    "Also I have learned that many simple steps can yield more insight than a complicated step. If we go through a process of data manipuation and classification sequentially it is easier for the reader to understanding the logical steps taken to arrive at conclusions. Also in trying to find ways to attack the problem I have spent weeks in 'analysis paralysis' when perhaps I should have started expertimenting sooner. Data Science is not so much a science as a set of tools for building a plausible narrative. A Data Scientist is perhaps more of a data storyteller or an insight advocate. It's important to recognise the limitations of technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nltk]",
   "language": "python",
   "name": "conda-env-nltk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
